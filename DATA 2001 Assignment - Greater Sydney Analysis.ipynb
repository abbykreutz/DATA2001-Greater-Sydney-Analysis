{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a824339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries and spatial packages\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130d52e",
   "metadata": {},
   "source": [
    "# Task 1: Import all datasets (clean if required) into your PostgreSQL server, using a well-defined data schema. T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16512a3c",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550ba131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Businesses dataset\n",
    "businesses_rawdf = pd.read_csv('Businesses.csv')\n",
    "businesses = businesses_rawdf.copy() # prepare a working copy\n",
    "\n",
    "# Import Stops dataset\n",
    "stops_rawdf = pd.read_csv('Stops.txt', delimiter=',')\n",
    "stops_df = stops_rawdf.copy() # prepare a working copy\n",
    "\n",
    "# Import Polls dataset\n",
    "polls_rawdf = pd.read_csv('PollingPlaces2019.csv')\n",
    "polls_df = polls_rawdf.copy() # prepare a working copy\n",
    "\n",
    "\n",
    "# Import Population dataset\n",
    "population_rawdf = pd.read_csv('Population.csv')\n",
    "population_df = population_rawdf.copy() # prepare a working copy\n",
    "\n",
    "# Import Income dataset\n",
    "income_rawdf = pd.read_csv('Income.csv')\n",
    "income_df = income_rawdf.copy() # prepare a working copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ad9f6",
   "metadata": {},
   "source": [
    "## Load Spatial Data (shapefiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00530c64",
   "metadata": {},
   "source": [
    "### Geopandas Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13d0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform polls dataset\n",
    "polls_df['geom'] = gpd.points_from_xy(polls_df.longitude, polls_df.latitude)  # creating the geometry column\n",
    "polls_df = polls_df.drop(columns=['latitude', 'longitude', 'the_geom'])  # removing the old latitude/longitude fields\n",
    "\n",
    "# Transform stops dataset\n",
    "stops_df['geom'] = gpd.points_from_xy(stops_df.stop_lon, stops_df.stop_lat)  # creating the geometry column\n",
    "stops_df = stops_df.drop(columns=['stop_lat', 'stop_lon'])  # removing the old latitude/longitude fields\n",
    "\n",
    "# Load sa2_regions dataset\n",
    "sa2_regions_path = 'SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp'\n",
    "sa2_regions_rawgdf = gpd.read_file(sa2_regions_path)\n",
    "\n",
    "# Load Schools dataset\n",
    "future_gdf = gpd.read_file('catchments/catchments_future.shp')\n",
    "primary_gdf = gpd.read_file('catchments/catchments_primary.shp')\n",
    "secondary_gdf = gpd.read_file('catchments/catchments_secondary.shp')\n",
    "schools_gdf = gpd.GeoDataFrame(pd.concat([future_gdf, primary_gdf, secondary_gdf], ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8753f",
   "metadata": {},
   "source": [
    "## Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93533189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import json\n",
    "\n",
    "credentials = \"Credentials copy.json\"\n",
    "\n",
    "# Helper functions provided in tutorial and recommended to be used in Ed\n",
    "\n",
    "def pgconnect(credentials_filepath, db_schema=\"public\"):\n",
    "    with open(credentials_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        host         = db_conn_dict['host']\n",
    "        db_user      = db_conn_dict['user']\n",
    "        db_pw        = db_conn_dict['password']\n",
    "        default_db   = db_conn_dict['database']\n",
    "        port         = db_conn_dict['port']\n",
    "        try:\n",
    "            db = create_engine(f'postgresql://{db_user}:{db_pw}@{host}:{port}/{default_db}', echo=False)\n",
    "            conn = db.connect()\n",
    "            print('Connected successfully.')\n",
    "        except Exception as e:\n",
    "            print(\"Unable to connect to the database.\")\n",
    "            print(e)\n",
    "            db, conn = None, None\n",
    "        return db, conn\n",
    "\n",
    "def query(conn, sqlcmd, args=None, df=True):\n",
    "    result = pd.DataFrame() if df else None\n",
    "    try:\n",
    "        if df:\n",
    "            result = pd.read_sql_query(sqlcmd, conn, params=args)\n",
    "        else:\n",
    "            result = conn.execute(text(sqlcmd), args).fetchall()\n",
    "            result = result[0] if len(result) == 1 else result\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered: \", e, sep='\\n')\n",
    "    return result\n",
    "\n",
    "db, conn = pgconnect(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381a3cd",
   "metadata": {},
   "source": [
    "### SRID Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c4447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SRID transformations\n",
    "\n",
    "srid = 4326\n",
    "\n",
    "def create_wkt_element(geom, srid):\n",
    "    if geom is not None:\n",
    "        if geom.geom_type == 'Polygon':\n",
    "            geom = MultiPolygon([geom])\n",
    "        return WKTElement(geom.wkt, srid)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# sa2_Regions Dataset\n",
    "sa2_regions_gdf = sa2_regions_rawgdf.copy()  # creating a copy of the original for later\n",
    "sa2_regions_gdf['geom'] = sa2_regions_gdf['geometry'].apply(lambda x: create_wkt_element(geom=x,srid=srid))  # applying the function\n",
    "sa2_regions_gdf = sa2_regions_gdf.drop(columns=\"geometry\")  # deleting the old copy\n",
    "\n",
    "# Stops dataset\n",
    "stops_df['geom'] = stops_df['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid)) # srid transformation\n",
    "\n",
    "# Polls dataset\n",
    "polls_df['geom'] = polls_df['geom'].apply(lambda x: WKTElement(x.wkt, srid=srid)) # srid transformation\n",
    "\n",
    "# Schools dataset\n",
    "schools_gdf['geom'] = schools_gdf['geometry'].apply(lambda x: create_wkt_element(geom=x, srid=srid)) # srid transformation applying function\n",
    "schools_gdf = schools_gdf.drop(columns=\"geometry\")  # deleting the old copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f1e4b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14009f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa2_regions \n",
    "sa2_regions_gdf = sa2_regions_gdf[['SA2_CODE21', 'SA2_NAME21', 'SA3_CODE21', 'SA3_NAME21', 'SA4_CODE21', 'SA4_NAME21', 'GCC_NAME21', 'AREASQKM21', 'geom']] # filter desired columns\n",
    "column_mapping = {col: col.lower() for col in sa2_regions_gdf.columns} # Map original column names to lowercase\n",
    "sa2_regions_gdf = sa2_regions_gdf.rename(columns=column_mapping) # Rename columns with lowercase names\n",
    "sa2_regions = sa2_regions_gdf.rename(columns={'sa2_code21' : 'sa2_code', \n",
    "                                              'sa2_name21' : 'sa2_name', \n",
    "                                              'sa3_code21' : 'sa3_code', \n",
    "                                              'sa3_name21' : 'sa3_name', \n",
    "                                              'sa4_code21' : 'sa4_code', \n",
    "                                              'sa4_name21' : 'sa4_name', \n",
    "                                              'gcc_name21' : 'gcc_name', \n",
    "                                              'areasqkm21' : 'area_sqkm'}) # implement normalized naming conventions\n",
    "    \n",
    "# businesses - no cleaning required\n",
    "\n",
    "# stops\n",
    "stops = stops_df[['stop_id', 'stop_name', 'parent_station', 'geom']] # select desired columns\n",
    "\n",
    "# polls\n",
    "polls = polls_df[['division_id', 'division_name', 'polling_place_id', 'polling_place_name', 'geom']] # filter desired columns\n",
    "\n",
    "\n",
    "# schools\n",
    "schools_gdf = schools_gdf[['USE_ID', 'CATCH_TYPE', 'USE_DESC', 'geom']] # filter desired columns\n",
    "column_mapping = {col: col.lower() for col in schools_gdf.columns} # Map original column names to lowercase\n",
    "schools_gdf = schools_gdf.rename(columns=column_mapping) # Rename columns with lowercase names\n",
    "schools = schools_gdf.rename(columns={'use_id' : 'school_id', \n",
    "                                      'catch_type' : 'school_type', \n",
    "                                      'use_desc' : 'school_name'}) # implement normalized naming conventions\n",
    "    \n",
    "# population\n",
    "population = population_df[['sa2_code', 'sa2_name', '0-4_people', '5-9_people', '10-14_people', '15-19_people', 'total_people']] # filter desired columns (for scoring)\n",
    "\n",
    "# income\n",
    "income = income_df.rename(columns={'sa2_code21' : 'sa2_code'}) # normnalize naming conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61068ebe",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a62f24",
   "metadata": {},
   "source": [
    "### Define schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d4467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SA2Regions table\n",
    "conn.execute(text('''\n",
    "DROP TABLE IF EXISTS sa2_regions CASCADE;\n",
    "CREATE TABLE sa2_regions (\n",
    "    sa2_code VARCHAR(9) PRIMARY KEY,\n",
    "    sa2_name VARCHAR(255),\n",
    "    sa3_code VARCHAR(5),\n",
    "    sa3_name VARCHAR(255),\n",
    "    sa4_code VARCHAR(3),\n",
    "    sa4_name VARCHAR(255),\n",
    "    gcc_name VARCHAR(255),\n",
    "    area_sqkm NUMERIC,\n",
    "    geom GEOMETRY(MULTIPOLYGON, 4326),\n",
    "    CONSTRAINT unique_sa2_code UNIQUE (sa2_code),\n",
    "    CONSTRAINT unique_sa2_name UNIQUE (sa2_name)\n",
    ");'''\n",
    "))\n",
    "\n",
    "# Create Businesses table\n",
    "conn.execute(text('''\n",
    "    DROP TABLE IF EXISTS businesses;\n",
    "    CREATE TABLE businesses (\n",
    "    industry_code VARCHAR(2),\n",
    "    industry_name VARCHAR(255),\n",
    "    sa2_code VARCHAR(9) REFERENCES sa2_regions(sa2_code),\n",
    "    sa2_name VARCHAR(255) REFERENCES sa2_regions(sa2_name),\n",
    "    \"0_to_50k_businesses\" INTEGER,\n",
    "    \"50k_to_200k_businesses\" INTEGER,\n",
    "    \"200k_to_2m_businesses\" INTEGER,\n",
    "    \"2m_to_5m_businesses\" INTEGER,\n",
    "    \"5m_to_10m_businesses\" INTEGER,\n",
    "    \"10m_or_more_businesses\" INTEGER,\n",
    "    total_businesses INTEGER,\n",
    "    PRIMARY KEY (sa2_code)\n",
    ");'''\n",
    "))\n",
    "\n",
    "# Create Stops table\n",
    "conn.execute(text('''\n",
    "DROP TABLE IF EXISTS stops;\n",
    "CREATE TABLE stops (\n",
    "    stop_id VARCHAR(8) PRIMARY KEY,\n",
    "    stop_name VARCHAR(255),\n",
    "    parent_station VARCHAR(8),\n",
    "    geom GEOMETRY(POINT, 4326)\n",
    ");'''\n",
    "))\n",
    "\n",
    "# Create Polls table\n",
    "conn.execute(text('''\n",
    "DROP TABLE IF EXISTS polls;\n",
    "CREATE TABLE polls (\n",
    "    division_id VARCHAR(3),\n",
    "    division_name VARCHAR(255),\n",
    "    polling_place_id VARCHAR(10) PRIMARY KEY,\n",
    "    polling_place_name VARCHAR(255),\n",
    "    geom GEOMETRY(POINT, 4326)\n",
    ");'''\n",
    "))\n",
    "\n",
    "# Create Schools table\n",
    "conn.execute(text('''\n",
    "DROP TABLE IF EXISTS schools;\n",
    "CREATE TABLE schools (\n",
    "    school_id VARCHAR(5) PRIMARY KEY,\n",
    "    school_type VARCHAR(25),\n",
    "    school_name VARCHAR(255),\n",
    "    geom GEOMETRY(MULTIPOLYGON, 4326)\n",
    ");'''\n",
    "))\n",
    "\n",
    "# Create Population table\n",
    "conn.execute(text('''\n",
    "DROP TABLE IF EXISTS population;\n",
    "CREATE TABLE population (\n",
    "    sa2_code VARCHAR(9) REFERENCES sa2_regions(sa2_code),\n",
    "    sa2_name VARCHAR(255) REFERENCES sa2_regions(sa2_name),\n",
    "    \"0-4_people\" INTEGER, \n",
    "    \"5-9_people\" INTEGER, \n",
    "    \"10-14_people\" INTEGER, \n",
    "    \"15-19_people\" INTEGER, \n",
    "    total_people INTEGER,\n",
    "    PRIMARY KEY (sa2_code)\n",
    ");'''\n",
    "))\n",
    "\n",
    "# Create Income table\n",
    "conn.execute(text('''\n",
    "DROP TABLE IF EXISTS income;\n",
    "CREATE TABLE income (\n",
    "    sa2_code VARCHAR(9) REFERENCES sa2_regions(sa2_code),\n",
    "    sa2_name VARCHAR(255) REFERENCES sa2_regions(sa2_name),\n",
    "    earners INTEGER,\n",
    "    median_age INTEGER,\n",
    "    median_income INTEGER,\n",
    "    mean_income INTEGER,\n",
    "    PRIMARY KEY (sa2_code)\n",
    ");'''\n",
    "))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b385f",
   "metadata": {},
   "source": [
    "### Populate newly created tables in our database with cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ae47be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa2_regions table populated successfully.\n",
      "businesses table populated successfully.\n",
      "stops table populated successfully.\n",
      "polls table populated successfully.\n",
      "schools table populated successfully.\n",
      "population table populated successfully.\n",
      "income table populated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Populate newly created tables in our database with cleaned data\n",
    "try:\n",
    "    # sa2_regions table\n",
    "    sa2_regions.to_sql('sa2_regions', con=conn, if_exists='append', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "    print(\"sa2_regions table populated successfully.\")\n",
    "    #print(query(conn, \"select * from sa2_regions\"))\n",
    "except Exception as e:\n",
    "    print(\"Error populating sa2_regions table:\", e)\n",
    "\n",
    "try:\n",
    "    # businesses table\n",
    "    businesses.to_sql('businesses', con=conn, if_exists='replace', index=False)\n",
    "    print(\"businesses table populated successfully.\")\n",
    "    #print(query(conn, \"select * from businesses\"))\n",
    "except Exception as e:\n",
    "    print(\"Error populating businesses table:\", e)\n",
    "\n",
    "try:\n",
    "    # stops table\n",
    "    stops.to_sql('stops', con=conn, if_exists='replace', index=False, dtype={'geom': Geometry('POINT', srid)})\n",
    "    print(\"stops table populated successfully.\")\n",
    "    #print(query(conn, \"select * from stops\"))\n",
    "except Exception as e:\n",
    "    print(\"Error populating stops table:\", e)\n",
    "\n",
    "try:\n",
    "    # polls table\n",
    "    polls.to_sql('polls', con=conn, if_exists='replace', index=False, dtype={'geom': Geometry('POINT', srid)})\n",
    "    print(\"polls table populated successfully.\")\n",
    "    #print(query(conn, \"select * from polls\"))\n",
    "except Exception as e:\n",
    "    print(\"Error populating polls table:\", e)\n",
    "\n",
    "try:\n",
    "    # schools table\n",
    "    schools.to_sql('schools', con=conn, if_exists='replace', index=False, dtype={'geom': Geometry('MULTIPOLYGON', srid)})\n",
    "    print(\"schools table populated successfully.\")\n",
    "    #print(query(conn, \"select * from schools\"))\n",
    "except Exception as e:\n",
    "    print(\"Error populating schools table:\", e)\n",
    "\n",
    "try:\n",
    "    # population table\n",
    "    population.to_sql('population', con=conn, if_exists='replace', index=False)\n",
    "    print(\"population table populated successfully.\")\n",
    "    #print(query(conn, \"select * from population\"))\n",
    "except Exception as e:\n",
    "    print(\"Error populating population table:\", e)\n",
    "\n",
    "try:\n",
    "    # income table\n",
    "    income.to_sql('income', con=conn, if_exists='replace', index=False)\n",
    "    print(\"income table populated successfully.\")\n",
    "    #print(query(conn, \"select * from income\"))\n",
    "except Exception as e:\n",
    "    print(\"Error populating income table:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36767e52-44d1-4b8d-ba73-29d48836cdaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      MULTIPOLYGON (((151.49562 -33.21384, 151.49529...\n",
      "1      MULTIPOLYGON (((151.55449 -33.22373, 151.55446...\n",
      "2      MULTIPOLYGON (((151.41636 -33.23597, 151.41699...\n",
      "3      MULTIPOLYGON (((151.41942 -33.26326, 151.42042...\n",
      "4      MULTIPOLYGON (((151.49651 -33.24227, 151.49830...\n",
      "                             ...                        \n",
      "725    MULTIPOLYGON (((151.76003 -32.92809, 151.76044...\n",
      "726    MULTIPOLYGON (((151.62164 -32.89473, 151.62241...\n",
      "727    MULTIPOLYGON (((151.76261 -32.90964, 151.76276...\n",
      "728    MULTIPOLYGON (((151.70159 -32.89717, 151.70121...\n",
      "729    MULTIPOLYGON (((151.72847 -32.89970, 151.72821...\n",
      "Name: geometry, Length: 730, dtype: geometry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/pss02ks15hj4547twb5z2vlc0000gn/T/ipykernel_53924/838888218.py:19: UserWarning: Geometry column does not contain geometry.\n",
      "  gdf['geometry'] = gdf['geometry'].apply(lambda geom: WKTElement(geom.wkt, srid=4326))\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "\n",
    "conn.execute(text('''\n",
    "DROP TABLE IF EXISTS homelessness;\n",
    "CREATE TABLE homelessness (\n",
    "    sa2_name_2016 VARCHAR(255) REFERENCES sa2_regions(sa2_name),\n",
    "    hl_p_homeless_tot INTEGER,\n",
    "    sa2_main16 VARCHAR(9) REFERENCES sa2_regions(sa2_code),\n",
    "    PRIMARY KEY (sa2_main16)\n",
    ");'''\n",
    "))\n",
    "\n",
    "homelessness_file = 'Homelessness NSW.json'\n",
    "gdf = gpd.read_file(homelessness_file)\n",
    "\n",
    "print(gdf['geometry'])\n",
    "attributes_to_keep = ['sa2_name_2016', 'hl_p_homeless_tot', 'sa2_main16', 'geometry']\n",
    "gdf = gdf[attributes_to_keep]\n",
    "gdf['geometry'] = gdf['geometry'].apply(lambda geom: WKTElement(geom.wkt, srid=4326))\n",
    "table_name = 'homelessness'\n",
    "gdf.to_sql(table_name, con=conn, if_exists='replace', index=False, dtype={'geometry': Geometry('MULTIPOLYGON', srid=4326)})\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f51981f-4b57-4328-b321-72128b113e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/pss02ks15hj4547twb5z2vlc0000gn/T/ipykernel_53924/3743862105.py:54: UserWarning: Geometry column does not contain geometry.\n",
      "  gdf['geometry'] = gdf['geometry'].apply(lambda geom: WKTElement(geom.wkt, srid=4326))\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "\n",
    "conn.execute(text('''\n",
    "DROP TABLE IF EXISTS energy;\n",
    "CREATE TABLE energy (\n",
    "    sa2_name_2011 VARCHAR(255) REFERENCES sa2_regions(sa2_name),\n",
    "    sa2_code_2011 VARCHAR(9) REFERENCES sa2_regions(sa2_code),\n",
    "    year INTEGER,\n",
    "    land_area_ha INTEGER,\n",
    "    wu_ag_area_ha INTEGER,\n",
    "    wu_irrigated_area_ha INTEGER,\n",
    "    wu_vol_wat_app_ml INTEGER,\n",
    "    wu_wat_oth_ag_use_ml INTEGER,\n",
    "    wu_tot_wat_user_ml INTEGER,\n",
    "    wu_app_rate_ml_per_ha INTEGER,\n",
    "    esg_gen_meters INTEGER,\n",
    "    esg_non_gen_meters INTEGER,\n",
    "    esg_tot_meters INTEGER,\n",
    "    esg_meter_dwell_gen_elec_pc INTEGER,\n",
    "    mksfg_net_meters_kwh INTEGER,\n",
    "    mksfg_gross_meters_kwh INTEGER,\n",
    "    mksfg_non_gen_meters_kwh INTEGER,\n",
    "    solar_panel_system INTEGER,\n",
    "    solar_water_heater INTEGER,\n",
    "    PRIMARY KEY (sa2_name_2011)\n",
    ");'''\n",
    "))\n",
    "\n",
    "energy_file = 'Energy NSW.json'\n",
    "gdf = gpd.read_file(energy_file)\n",
    "attributes_to_keep = [\n",
    "    'sa2_name_2011',\n",
    "    'sa2_code_2011',\n",
    "    'year',\n",
    "    'land_area_ha',\n",
    "    'wu_ag_area_ha',\n",
    "    'wu_irrigated_area_ha',\n",
    "    'wu_vol_wat_app_ml',\n",
    "    'wu_wat_oth_ag_use_ml',\n",
    "    'wu_tot_wat_use_ml',\n",
    "    'wu_app_rate_ml_per_ha',\n",
    "    'esg_gen_meters',\n",
    "    'esg_non_gen_meters',\n",
    "    'esg_tot_meters',\n",
    "    'esg_meter_dwell_gen_elec_pc',\n",
    "    'mksfg_net_meters_kwh',\n",
    "    'mksfg_gross_meters_kwh',\n",
    "    'mksfg_non_gen_meters_kwh',\n",
    "    'solar_panel_system',\n",
    "    'solar_water_heater',\n",
    "    'geometry'\n",
    "]\n",
    "gdf = gdf[attributes_to_keep]\n",
    "gdf['geometry'] = gdf['geometry'].apply(lambda geom: WKTElement(geom.wkt, srid=4326))\n",
    "table_name = 'energy'\n",
    "gdf.to_sql(table_name, con=conn, if_exists='replace', index=False, dtype={'geometry': Geometry('MULTIPOLYGON', srid=4326)})\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50221ebb",
   "metadata": {},
   "source": [
    "# Task 2: Compute a score for how ”bustling” each individual neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6578cce9-dbc4-447a-95af-1aa9f0753c4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"z_businesses_pkey\"\nDETAIL:  Key (sa2_code)=(121041414) already exists.\n\n[SQL: \nCREATE TABLE IF NOT EXISTS z_businesses (\n    sa2_code VARCHAR(9) PRIMARY KEY,\n    region_score NUMERIC, -- Rename the existing z-score column\n    z_score NUMERIC -- New z-score column based on region_score\n);\n\nWITH region_scores AS (\n    SELECT \n        sa.sa2_code::text AS sa2_code,\n        (SUM(b.total_businesses)::float / pop.total_people * 1000) AS region_score\n    FROM \n        sa2_regions sa\n    LEFT JOIN \n        businesses b ON sa.sa2_code::bigint = b.sa2_code::bigint\n    LEFT JOIN \n        population pop ON sa.sa2_code::text = pop.sa2_code::text\n    WHERE \n        pop.total_people >= 100\n    GROUP BY \n        sa.sa2_code, pop.total_people\n)\n\nINSERT INTO z_businesses (sa2_code, region_score)\nSELECT \n    sa2_code,\n    region_score\nFROM \n    region_scores;\n\nWITH stats AS (\n    SELECT \n        AVG(region_score) AS mean_region_score,\n        STDDEV(region_score) AS stddev_region_score\n    FROM \n        z_businesses\n)\n\nUPDATE z_businesses\nSET z_score = (region_score - mean_region_score) / stddev_region_score\nFROM stats;\n]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUniqueViolation\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1971\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1971\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[1;32m   1972\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1973\u001b[0m         )\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/default.py:919\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 919\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mUniqueViolation\u001b[0m: duplicate key value violates unique constraint \"z_businesses_pkey\"\nDETAIL:  Key (sa2_code)=(121041414) already exists.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 45\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mCREATE TABLE IF NOT EXISTS z_businesses (\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    sa2_code VARCHAR(9) PRIMARY KEY,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124mFROM stats;\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Execute the query\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m conn\u001b[38;5;241m.\u001b[39mexecute(text(query))\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Commit the changes\u001b[39;00m\n\u001b[1;32m     48\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1422\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\n\u001b[1;32m   1423\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1424\u001b[0m         distilled_parameters,\n\u001b[1;32m   1425\u001b[0m         execution_options \u001b[38;5;129;01mor\u001b[39;00m NO_OPTIONS,\n\u001b[1;32m   1426\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:514\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39m_execute_clauseelement(\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;28mself\u001b[39m, distilled_params, execution_options\n\u001b[1;32m    516\u001b[0m     )\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1644\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1632\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1634\u001b[0m )\n\u001b[1;32m   1636\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1637\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1638\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1643\u001b[0m )\n\u001b[0;32m-> 1644\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[1;32m   1645\u001b[0m     dialect,\n\u001b[1;32m   1646\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[1;32m   1647\u001b[0m     compiled_sql,\n\u001b[1;32m   1648\u001b[0m     distilled_parameters,\n\u001b[1;32m   1649\u001b[0m     execution_options,\n\u001b[1;32m   1650\u001b[0m     compiled_sql,\n\u001b[1;32m   1651\u001b[0m     distilled_parameters,\n\u001b[1;32m   1652\u001b[0m     elem,\n\u001b[1;32m   1653\u001b[0m     extracted_params,\n\u001b[1;32m   1654\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[1;32m   1655\u001b[0m )\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1658\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1659\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1663\u001b[0m         ret,\n\u001b[1;32m   1664\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1850\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_single_context(\n\u001b[1;32m   1851\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1852\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1990\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1990\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[1;32m   1991\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1992\u001b[0m     )\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2357\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2356\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2359\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1971\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1969\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1971\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[1;32m   1972\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1973\u001b[0m         )\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1976\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1977\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1978\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1982\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1983\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/default.py:919\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 919\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"z_businesses_pkey\"\nDETAIL:  Key (sa2_code)=(121041414) already exists.\n\n[SQL: \nCREATE TABLE IF NOT EXISTS z_businesses (\n    sa2_code VARCHAR(9) PRIMARY KEY,\n    region_score NUMERIC, -- Rename the existing z-score column\n    z_score NUMERIC -- New z-score column based on region_score\n);\n\nWITH region_scores AS (\n    SELECT \n        sa.sa2_code::text AS sa2_code,\n        (SUM(b.total_businesses)::float / pop.total_people * 1000) AS region_score\n    FROM \n        sa2_regions sa\n    LEFT JOIN \n        businesses b ON sa.sa2_code::bigint = b.sa2_code::bigint\n    LEFT JOIN \n        population pop ON sa.sa2_code::text = pop.sa2_code::text\n    WHERE \n        pop.total_people >= 100\n    GROUP BY \n        sa.sa2_code, pop.total_people\n)\n\nINSERT INTO z_businesses (sa2_code, region_score)\nSELECT \n    sa2_code,\n    region_score\nFROM \n    region_scores;\n\nWITH stats AS (\n    SELECT \n        AVG(region_score) AS mean_region_score,\n        STDDEV(region_score) AS stddev_region_score\n    FROM \n        z_businesses\n)\n\nUPDATE z_businesses\nSET z_score = (region_score - mean_region_score) / stddev_region_score\nFROM stats;\n]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS z_businesses (\n",
    "    sa2_code VARCHAR(9) PRIMARY KEY,\n",
    "    region_score NUMERIC, -- Rename the existing z-score column\n",
    "    z_score NUMERIC -- New z-score column based on region_score\n",
    ");\n",
    "\n",
    "WITH region_scores AS (\n",
    "    SELECT \n",
    "        sa.sa2_code::text AS sa2_code,\n",
    "        (SUM(b.total_businesses)::float / pop.total_people * 1000) AS region_score\n",
    "    FROM \n",
    "        sa2_regions sa\n",
    "    LEFT JOIN \n",
    "        businesses b ON sa.sa2_code::bigint = b.sa2_code::bigint\n",
    "    LEFT JOIN \n",
    "        population pop ON sa.sa2_code::text = pop.sa2_code::text\n",
    "    WHERE \n",
    "        pop.total_people >= 100\n",
    "    GROUP BY \n",
    "        sa.sa2_code, pop.total_people\n",
    ")\n",
    "\n",
    "INSERT INTO z_businesses (sa2_code, region_score)\n",
    "SELECT \n",
    "    sa2_code,\n",
    "    region_score\n",
    "FROM \n",
    "    region_scores;\n",
    "\n",
    "WITH stats AS (\n",
    "    SELECT \n",
    "        AVG(region_score) AS mean_region_score,\n",
    "        STDDEV(region_score) AS stddev_region_score\n",
    "    FROM \n",
    "        z_businesses\n",
    ")\n",
    "\n",
    "UPDATE z_businesses\n",
    "SET z_score = (region_score - mean_region_score) / stddev_region_score\n",
    "FROM stats;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "conn.execute(text(query))\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45481991-f5f0-491c-aaff-82364dfd7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS z_stops (\n",
    "    sa2_code VARCHAR(9) PRIMARY KEY,\n",
    "    region_score NUMERIC,\n",
    "    z_score NUMERIC\n",
    ");\n",
    "\n",
    "WITH z_scores AS (\n",
    "    SELECT \n",
    "        sa.sa2_code::text AS sa2_code,\n",
    "        (COUNT(s.stop_id)::float / pop.total_people * 1000) AS region_score\n",
    "    FROM \n",
    "        sa2_regions sa\n",
    "    LEFT JOIN \n",
    "        stops s ON ST_Contains(sa.geom, s.geom)\n",
    "    LEFT JOIN \n",
    "        population pop ON sa.sa2_code::text = pop.sa2_code::text\n",
    "    WHERE \n",
    "        pop.total_people >= 100\n",
    "    GROUP BY \n",
    "        sa.sa2_code, pop.total_people\n",
    ")\n",
    "\n",
    "INSERT INTO z_stops (sa2_code, region_score)\n",
    "SELECT \n",
    "    sa2_code,\n",
    "    region_score\n",
    "FROM \n",
    "    z_scores;\n",
    "\n",
    "UPDATE z_stops SET z_score = (region_score - avg_score) / stddev_score\n",
    "FROM (\n",
    "    SELECT \n",
    "        AVG(region_score) AS avg_score,\n",
    "        STDDEV(region_score) AS stddev_score\n",
    "    FROM \n",
    "        z_stops\n",
    ") AS stats;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "conn.execute(text(query))\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac892bee-d06b-41b4-96b6-303cd531a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS z_polls (\n",
    "    sa2_code VARCHAR(9) PRIMARY KEY,\n",
    "    region_score NUMERIC,\n",
    "    z_score NUMERIC\n",
    ");\n",
    "\n",
    "WITH z_scores AS (\n",
    "    SELECT \n",
    "        sa.sa2_code::text AS sa2_code,\n",
    "        (COUNT(p.polling_place_id)::float / pop.total_people * 1000) AS region_score\n",
    "    FROM \n",
    "        sa2_regions sa\n",
    "    LEFT JOIN \n",
    "        polls p ON ST_Contains(sa.geom, p.geom)\n",
    "    LEFT JOIN \n",
    "        population pop ON sa.sa2_code::text = pop.sa2_code::text\n",
    "    WHERE \n",
    "        pop.total_people >= 100\n",
    "    GROUP BY \n",
    "        sa.sa2_code, pop.total_people\n",
    ")\n",
    "\n",
    "INSERT INTO z_polls (sa2_code, region_score)\n",
    "SELECT \n",
    "    sa2_code,\n",
    "    region_score\n",
    "FROM \n",
    "    z_scores;\n",
    "\n",
    "UPDATE z_polls SET z_score = (region_score - avg_score) / stddev_score\n",
    "FROM (\n",
    "    SELECT \n",
    "        AVG(region_score) AS avg_score,\n",
    "        STDEV(region_score) AS stddev_score\n",
    "    FROM \n",
    "        z_polls\n",
    ") AS stats;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "conn.execute(text(query))\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2f0f7-44d4-4439-bfae-97f250eb7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS z_schools (\n",
    "    sa2_code VARCHAR(9) PRIMARY KEY,\n",
    "    region_score NUMERIC,\n",
    "    z_score NUMERIC\n",
    ");\n",
    "\n",
    "WITH z_scores AS (\n",
    "    SELECT \n",
    "        sa.sa2_code::text AS sa2_code,\n",
    "        (COUNT(sc.school_id)::float / (pop.\"0-4_people\" + pop.\"5-9_people\" + pop.\"10-14_people\" + pop.\"15-19_people\") * 1000) AS region_score\n",
    "    FROM \n",
    "        sa2_regions sa\n",
    "    LEFT JOIN \n",
    "        schools sc ON ST_Intersects(sa.geom, sc.geom)\n",
    "    LEFT JOIN \n",
    "        population pop ON sa.sa2_code::text = pop.sa2_code::text\n",
    "    WHERE \n",
    "        pop.total_people >= 100\n",
    "    GROUP BY \n",
    "        sa.sa2_code, pop.\"0-4_people\", pop.\"5-9_people\", pop.\"10-14_people\", pop.\"15-19_people\"\n",
    ")\n",
    "\n",
    "INSERT INTO z_schools (sa2_code, region_score)\n",
    "SELECT \n",
    "    sa2_code,\n",
    "    region_score\n",
    "FROM \n",
    "    z_scores;\n",
    "\n",
    "UPDATE z_schools SET z_score = (region_score - avg_score) / stddev_score\n",
    "FROM (\n",
    "    SELECT \n",
    "        AVG(region_score) AS avg_score,\n",
    "        STDEV(region_score) AS stddev_score\n",
    "    FROM \n",
    "        z_schools\n",
    ") AS stats;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "conn.execute(text(query))\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56643a15-7c7d-4402-87f5-80915b0978b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS well_resourced_score (\n",
    "    sa2_code VARCHAR(9) PRIMARY KEY,\n",
    "    score NUMERIC\n",
    ");\n",
    "\n",
    "INSERT INTO well_resourced_score (sa2_code, score)\n",
    "SELECT\n",
    "    z_businesses.sa2_code,\n",
    "    1 / (1 + EXP(- (z_businesses.z_score + z_stops.z_score + z_polls.z_score + z_schools.z_score))) AS well_resourced_score\n",
    "FROM\n",
    "    z_businesses\n",
    "JOIN\n",
    "    z_stops ON z_businesses.sa2_code = z_stops.sa2_code\n",
    "JOIN\n",
    "    z_polls ON z_businesses.sa2_code = z_polls.sa2_code\n",
    "JOIN\n",
    "    z_schools ON z_businesses.sa2_code = z_schools.sa2_code;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "conn.execute(text(query))\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
